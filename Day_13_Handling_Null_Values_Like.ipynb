{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K9R9pyy1gU2Z"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with a longer timeout\n",
        "# drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "\n",
        "# df_employee_data = \"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\"\n",
        "# employeeSechema = StructType([\n",
        "#     StructField(\"ID\",IntegerType() ,True),\n",
        "#     StructField(\"Name\",StringType() ,True),\n",
        "#     StructField(\"Age\",IntegerType() ,True),\n",
        "#     StructField(\"Salary\",FloatType() ,True),\n",
        "#     StructField(\"Joining_Date\",DateType() ,True),\n",
        "#     StructField(\"Department\",StringType() ,True),\n",
        "#     StructField(\"Performance_Rating\",IntegerType() ,True),\n",
        "#     StructField(\"Email\",StringType() ,True),\n",
        "#     StructField(\"Address\",StringType() ,True),\n",
        "#     StructField(\"Phone\",StringType() ,True)\n",
        "\n",
        "# ])\n",
        "# # Load the DataFrame with the defined schema\n",
        "# #df = spark.read.csv(path=df_employee_data, header=True, schema=employeeSechema)\n",
        "# df = spark.read.load(path=\"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\", format=\"csv\", header = True, schema=employeeSechema)\n",
        "# df.printSchema()\n",
        "# df.show(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Null Handling in Dataframe"
      ],
      "metadata": {
        "id": "knP5wytcsBpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: sales data with nulls\n",
        "data = [\n",
        "      (\"John\", \"North\", 100, None),\n",
        "      (\"Doe\", \"East\", None, 50),\n",
        "      (None, \"West\", 150, 30),\n",
        "      (\"Alice\", None, 200, 40),\n",
        "      (\"Bob\", \"South\", None, None),\n",
        "      (None, None, None, None)\n",
        "  ]\n",
        "columns = [\"Name\", \"Region\", \"UnitsSold\", \"Revenue\"]\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IFVtqhI2sDrR",
        "outputId": "974aa4e9-a443-4df0-bc36-5e8e4f93c1d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+-------+\n",
            "| Name|Region|UnitsSold|Revenue|\n",
            "+-----+------+---------+-------+\n",
            "| John| North|      100|   NULL|\n",
            "|  Doe|  East|     NULL|     50|\n",
            "| NULL|  West|      150|     30|\n",
            "|Alice|  NULL|      200|     40|\n",
            "|  Bob| South|     NULL|   NULL|\n",
            "| NULL|  NULL|     NULL|   NULL|\n",
            "+-----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Detecting Null Values:\n",
        "* The isNull() function identifies rows where a specified column has null values. The output shows a boolean flag for each row to indicate whether the value in the column is null."
      ],
      "metadata": {
        "id": "KYx6hsEYskB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting Null Values in the \"Region\" column\n",
        "df.select(\"Name\", \"Region\", isnull(\"Region\").alias(\"is_Region_Null\")).show()"
      ],
      "metadata": {
        "id": "Axp49XOkspfE",
        "outputId": "01b211dc-51b8-404c-a0c7-05f86ddfd0f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+--------------+\n",
            "| Name|Region|is_Region_Null|\n",
            "+-----+------+--------------+\n",
            "| John| North|         false|\n",
            "|  Doe|  East|         false|\n",
            "| NULL|  West|         false|\n",
            "|Alice|  NULL|          true|\n",
            "|  Bob| South|         false|\n",
            "| NULL|  NULL|          true|\n",
            "+-----+------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Dropping Rows with Null Values:\n",
        "* dropna() removes rows that contain null values in any column when the default mode is used.\n",
        "* Specifying \"all\" ensures rows are only removed if all columns contain null values.\n",
        "* You can also apply null handling only on specific columns by providing a list of column names to the subset parameter."
      ],
      "metadata": {
        "id": "9FhBfMjStYRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Rows with Null values (if any value in the row is null)\n",
        "df2 = df.dropna()\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "QVFdtogys1JA",
        "outputId": "23c68728-c9b1-4fb1-f842-6f76695868cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+---------+-------+\n",
            "|Name|Region|UnitsSold|Revenue|\n",
            "+----+------+---------+-------+\n",
            "+----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping rows where all values are null"
      ],
      "metadata": {
        "id": "cq5OlpjAt7Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.na.drop(\"all\")\n",
        "df3.show()"
      ],
      "metadata": {
        "id": "GSXkeSqVtpSh",
        "outputId": "c14ca914-1ce9-4110-ebe3-f7931a262934",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+-------+\n",
            "| Name|Region|UnitsSold|Revenue|\n",
            "+-----+------+---------+-------+\n",
            "| John| North|      100|   NULL|\n",
            "|  Doe|  East|     NULL|     50|\n",
            "| NULL|  West|      150|     30|\n",
            "|Alice|  NULL|      200|     40|\n",
            "|  Bob| South|     NULL|   NULL|\n",
            "+-----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pending page 38"
      ],
      "metadata": {
        "id": "c-i5G8Szuc2b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhZ0wTu4uKTj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}