{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMO6GL+0B14ho+6+yljlO60"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNJLquix15XZ",
        "outputId": "343530b6-06c6-4ee2-df9a-fbe831cafa92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with a longer timeout\n",
        "drive.mount('/content/drive', force_remount=True, timeout_ms=300000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_employee_data = \"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\"\n",
        "employeeSechema = StructType([\n",
        "    StructField(\"ID\",IntegerType() ,True),\n",
        "    StructField(\"Name\",StringType() ,True),\n",
        "    StructField(\"Age\",IntegerType() ,True),\n",
        "    StructField(\"Salary\",FloatType() ,True),\n",
        "    StructField(\"Joining_Date\",DateType() ,True),\n",
        "    StructField(\"Department\",StringType() ,True),\n",
        "    StructField(\"Performance_Rating\",IntegerType() ,True),\n",
        "    StructField(\"Email\",StringType() ,True),\n",
        "    StructField(\"Address\",StringType() ,True),\n",
        "    StructField(\"Phone\",StringType() ,True)\n",
        "\n",
        "])\n",
        "# Load the DataFrame with the defined schema\n",
        "#df = spark.read.csv(path=df_employee_data, header=True, schema=employeeSechema)\n",
        "df = spark.read.load(path=\"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\", format=\"csv\", header = True, schema=employeeSechema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spqcyB7n2itR",
        "outputId": "5f574f90-54a4-470f-c185-4871cd42396f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Salary: float (nullable = true)\n",
            " |-- Joining_Date: date (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Performance_Rating: integer (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- Address: string (nullable = true)\n",
            " |-- Phone: string (nullable = true)\n",
            "\n",
            "+---+-------------+---+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "| ID|         Name|Age| Salary|Joining_Date| Department|Performance_Rating|               Email|           Address|       Phone|\n",
            "+---+-------------+---+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "|  1|Alice Johnson| 29|75000.0|  2021-03-15|Engineering|                 4|alice.johnson@exa...|123 Elm Street, NY|123-456-7890|\n",
            "|  2|    Bob Smith| 35|85000.0|  2020-08-20|  Marketing|                 5|bob.smith@example...|456 Oak Avenue, LA|987-654-3210|\n",
            "|  3|  Cathy Brown| 42|95000.0|  2019-11-10|    Finance|                 3|cathy.brown@examp...| 789 Pine Road, TX|567-890-1234|\n",
            "|  4|  David White| 30|67000.0|  2022-01-05|         HR|                 4|david.white@examp...|234 Maple Lane, IL|345-678-9012|\n",
            "|  5|    Eva Green| 28|72000.0|  2023-06-22|Engineering|                 5|eva.green@example...|321 Birch Blvd, FL|234-567-8901|\n",
            "+---+-------------+---+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark DataFrame Manipulation part 2: Adding, Renaming, and Dropping Columns"
      ],
      "metadata": {
        "id": "OcPZNOTh25uI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Adding New Columns with withColumn()\n",
        "\n",
        "In PySpark, the withColumn() function is widely used to add new columns to a DataFrame. You can either assign a constant value using lit() or perform transformations using existing columns."
      ],
      "metadata": {
        "id": "aaBw1jPx2-5O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hO1VzFW386hS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}