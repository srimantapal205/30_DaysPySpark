{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "root\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Salary: float (nullable = true)\n",
            " |-- Joining_Date: date (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Performance_Rating: integer (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- Address: string (nullable = true)\n",
            " |-- Phone: string (nullable = true)\n",
            "\n",
            "+---+-------------+----+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "| ID|         Name| Age| Salary|Joining_Date| Department|Performance_Rating|               Email|           Address|       Phone|\n",
            "+---+-------------+----+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "|  1|Alice Johnson|  29|75000.0|  2021-03-15|Engineering|                 4|alice.johnson@exa...|123 Elm Street, NY|123-456-7890|\n",
            "|  2|    Bob Smith|  35|85000.0|  2020-08-20|  Marketing|                 5|bob.smith@example...|456 Oak Avenue, LA|987-654-3210|\n",
            "|  3|  Cathy Brown|  42|95000.0|  2019-11-10|    Finance|                 3|cathy.brown@examp...| 789 Pine Road, TX|567-890-1234|\n",
            "|  4|  David White|  30|67000.0|  2022-01-05|         HR|                 4|david.white@examp...|234 Maple Lane, IL|345-678-9012|\n",
            "|  5|    Eva Green|  28|72000.0|  2023-06-22|Engineering|                 5|eva.green@example...|321 Birch Blvd, FL|234-567-8901|\n",
            "|  6|        Alice|  29|55000.0|  2024-12-06|    Finance|                 6|   alice@example.com|235 Maple Lane, IL|345-678-9013|\n",
            "|  7|          Bob|NULL|38000.0|  2024-05-23|         HR|                 7|                Null|322 Birch Blvd, FL|234-567-8902|\n",
            "|  8|      Charlie|  27|21000.0|  2024-11-07|Engineering|                 8|     charlie@xyz.com|              Null|345-678-9014|\n",
            "|  9|         Emma|  31|40000.0|  2024-04-23|    Finance|                 9|        emma@abc.com|122 Elm Street, NY|234-567-8903|\n",
            "+---+-------------+----+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with a longer timeout\n",
        "# drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "\n",
        "# df_employee_data = \"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\"\n",
        "# employeeSechema = StructType([\n",
        "#     StructField(\"ID\",IntegerType() ,True),\n",
        "#     StructField(\"Name\",StringType() ,True),\n",
        "#     StructField(\"Age\",IntegerType() ,True),\n",
        "#     StructField(\"Salary\",FloatType() ,True),\n",
        "#     StructField(\"Joining_Date\",DateType() ,True),\n",
        "#     StructField(\"Department\",StringType() ,True),\n",
        "#     StructField(\"Performance_Rating\",IntegerType() ,True),\n",
        "#     StructField(\"Email\",StringType() ,True),\n",
        "#     StructField(\"Address\",StringType() ,True),\n",
        "#     StructField(\"Phone\",StringType() ,True)\n",
        "\n",
        "# ])\n",
        "# # Load the DataFrame with the defined schema\n",
        "# #df = spark.read.csv(path=df_employee_data, header=True, schema=employeeSechema)\n",
        "# df = spark.read.load(path=\"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\", format=\"csv\", header = True, schema=employeeSechema)\n",
        "# df.printSchema()\n",
        "# df.show(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slPrPwBoPLnS"
      },
      "source": [
        "### Create NewSpark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sJFEDlSfPLF7"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName('StrongAndStringFunction').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G9UJ2eoPzjZ",
        "outputId": "e64846f9-b4aa-436f-efa3-c03dd51e0bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-------------+---------+---------+\n",
            "|  Country|       Region|UnitsSold|UnitPrice|\n",
            "+---------+-------------+---------+---------+\n",
            "|      USA|North America|      100|     50.5|\n",
            "|    India|         Asia|      300|     20.0|\n",
            "|  Germany|       Europe|      200|     30.5|\n",
            "|Australia|      Oceania|      150|     60.0|\n",
            "|    Japan|         Asia|      120|     45.0|\n",
            "|   Brazil|South America|      180|     25.0|\n",
            "+---------+-------------+---------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Sample Data\n",
        "data = [(\"USA\", \"North America\", 100, 50.5), (\"India\", \"Asia\", 300, 20.0), (\"Germany\", \"Europe\", 200, 30.5), (\"Australia\", \"Oceania\", 150, 60.0), (\"Japan\", \"Asia\", 120, 45.0), (\"Brazil\", \"South America\", 180, 25.0) ]\n",
        "\n",
        "# Define Schema\n",
        "columns = [\"Country\", \"Region\", \"UnitsSold\", \"UnitPrice\"]\n",
        "\n",
        "#Create Dataframe\n",
        "df = spark.createDataFrame(data=data, schema=columns)\n",
        "\n",
        "# Display Orifinal Data Frame\n",
        "df.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWnqJmsuRbrU"
      },
      "source": [
        "## 1. Convert the first letter of each word to uppercase (initcap):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7-n5GmIT8HC",
        "outputId": "215eceb4-6ec2-47e9-e36d-b1f5c80f2ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+\n",
            "|initcap(Country)|\n",
            "+----------------+\n",
            "|             Usa|\n",
            "|           India|\n",
            "|         Germany|\n",
            "|       Australia|\n",
            "|           Japan|\n",
            "|          Brazil|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Apply initcap on the new DataFrame\n",
        "df.select(initcap(col(\"Country\"))).show() # Changed df to df_sample\n",
        "\n",
        "#Note: This transforms the first letter of each word in the Country column to uppercase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoI1WNofcMot"
      },
      "source": [
        "##2.Convert all text to lowercase (lower):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zH2Y2cyaXtz",
        "outputId": "13389284-9dd2-4f62-e96d-8cc1c6b02d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+\n",
            "|lower(Region)|\n",
            "+-------------+\n",
            "|north america|\n",
            "|         asia|\n",
            "|       europe|\n",
            "|      oceania|\n",
            "|         asia|\n",
            "|south america|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(lower(col('Region'))).show()\n",
        "#Note: Converts all letters in the Country column to lowercase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz6-MhdseXlq"
      },
      "source": [
        "## 3.Convert all text to uppercase (upper):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgIIW21Reex4",
        "outputId": "415d3e9a-1417-484d-cbd1-2666910069d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+\n",
            "|upper(Region)|\n",
            "+-------------+\n",
            "|NORTH AMERICA|\n",
            "|         ASIA|\n",
            "|       EUROPE|\n",
            "|      OCEANIA|\n",
            "|         ASIA|\n",
            "|SOUTH AMERICA|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(upper(col('Region'))).show()\n",
        "#Note:Converts all letters in the Country column to uppercase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp4GeVAWeu07"
      },
      "source": [
        "## Concatenation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYwWhXm4eoNL",
        "outputId": "c7d0362e-04e3-4168-9981-7eb09a686326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------+\n",
            "|concat(Region, Country)|\n",
            "+-----------------------+\n",
            "|       North AmericaUSA|\n",
            "|              AsiaIndia|\n",
            "|          EuropeGermany|\n",
            "|       OceaniaAustralia|\n",
            "|              AsiaJapan|\n",
            "|    South AmericaBrazil|\n",
            "+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(concat(col('Region'),col('Country'))).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvgIsjcPfsoZ"
      },
      "source": [
        "## 2.Concatenate with a separator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shs91KI3frtj",
        "outputId": "800fb43b-cf98-4838-e991-3091a3131d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------+\n",
            "|concat_ws(|, Region, Country)|\n",
            "+-----------------------------+\n",
            "|            North America|USA|\n",
            "|                   Asia|India|\n",
            "|               Europe|Germany|\n",
            "|            Oceania|Australia|\n",
            "|                   Asia|Japan|\n",
            "|         South America|Brazil|\n",
            "+-----------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(concat_ws('|', col('Region'), col('Country'))).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjuMf5WZgnvK"
      },
      "source": [
        "## 3.Create a new concatenated column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im3ZuPOJgnfE",
        "outputId": "0bbafa15-55c7-4907-aedf-6e2faa623a84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-------------+---------+---------+-----------------------+\n",
            "|  Country|       Region|UnitsSold|UnitPrice|Concatenated_new_column|\n",
            "+---------+-------------+---------+---------+-----------------------+\n",
            "|      USA|North America|      100|     50.5|    North America - USA|\n",
            "|    India|         Asia|      300|     20.0|           Asia - India|\n",
            "|  Germany|       Europe|      200|     30.5|       Europe - Germany|\n",
            "|Australia|      Oceania|      150|     60.0|    Oceania - Australia|\n",
            "|    Japan|         Asia|      120|     45.0|           Asia - Japan|\n",
            "|   Brazil|South America|      180|     25.0|   South America - B...|\n",
            "+---------+-------------+---------+---------+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "concated_df =df.withColumn('Concatenated_new_column', concat(col('Region'), lit(' - '),col('Country')))\n",
        "concated_df.show()\n",
        "\n",
        "#Note: This creates a new column concatenated by combining Region and Country with a space between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQOlq7WYfLIF"
      },
      "outputs": [],
      "source": [
        "d"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
