{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K9R9pyy1gU2Z"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with a longer timeout\n",
        "# drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "\n",
        "# df_employee_data = \"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\"\n",
        "# employeeSechema = StructType([\n",
        "#     StructField(\"ID\",IntegerType() ,True),\n",
        "#     StructField(\"Name\",StringType() ,True),\n",
        "#     StructField(\"Age\",IntegerType() ,True),\n",
        "#     StructField(\"Salary\",FloatType() ,True),\n",
        "#     StructField(\"Joining_Date\",DateType() ,True),\n",
        "#     StructField(\"Department\",StringType() ,True),\n",
        "#     StructField(\"Performance_Rating\",IntegerType() ,True),\n",
        "#     StructField(\"Email\",StringType() ,True),\n",
        "#     StructField(\"Address\",StringType() ,True),\n",
        "#     StructField(\"Phone\",StringType() ,True)\n",
        "\n",
        "# ])\n",
        "# # Load the DataFrame with the defined schema\n",
        "# #df = spark.read.csv(path=df_employee_data, header=True, schema=employeeSechema)\n",
        "# df = spark.read.load(path=\"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\", format=\"csv\", header = True, schema=employeeSechema)\n",
        "# df.printSchema()\n",
        "# df.show(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate function in Dataframe â€“ Part 1"
      ],
      "metadata": {
        "id": "knP5wytcsBpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample data\n",
        "data = [\n",
        "      Row(id=1, value=10),\n",
        "      Row(id=2, value=20),\n",
        "      Row(id=3, value=30),\n",
        "      Row(id=4, value=None),\n",
        "      Row(id=5, value=40),\n",
        "      Row(id=6, value=20)\n",
        "   ]\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "# Show the DataFrame\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt1te3ktVd2a",
        "outputId": "93738a03-83ab-4aec-8994-05061ed8bc33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id|value|\n",
            "+---+-----+\n",
            "|  1|   10|\n",
            "|  2|   20|\n",
            "|  3|   30|\n",
            "|  4| NULL|\n",
            "|  5|   40|\n",
            "|  6|   20|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Summation (sum): Sums up the values in a specified column."
      ],
      "metadata": {
        "id": "hhNBHWhQV_IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_sum = df.select(sum(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw9-mHgqWA8l",
        "outputId": "0f22b535-f42f-4e60-fbf5-c2e1b575d3d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|sum(value)|\n",
            "+----------+\n",
            "|       120|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.average of the values in a specified column."
      ],
      "metadata": {
        "id": "ymdYr8jCWe2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avarage_value = df.select(avg(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNZrE5gGWN1G",
        "outputId": "aae789d0-1ad0-4cb2-f215-dfe75bda2a2b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|avg(value)|\n",
            "+----------+\n",
            "|      24.0|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Count (count): Counts the number of non-null values in a specified column."
      ],
      "metadata": {
        "id": "RSh6ZXv0Wu_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_null_count = df.select(count(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXAycrynWrV7",
        "outputId": "0818aa3c-7b57-4df8-f1ca-d31d453b5c66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|count(value)|\n",
            "+------------+\n",
            "|           5|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.Maximum (max) and Minimum (min):\n",
        "* Finds the maximum and minimum values in a specified column"
      ],
      "metadata": {
        "id": "pE-6Pe-GW_z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_min_value = df.select(max(\"value\"), min(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL8AuZS5W-ep",
        "outputId": "7792f694-0e72-430a-86cc-5f9c0aff2c4f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|max(value)|min(value)|\n",
            "+----------+----------+\n",
            "|        40|        10|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distinct Values Count (countDistinct):\n",
        "  * Counts the number of distinct values in a specified column."
      ],
      "metadata": {
        "id": "2loPSMbCXfNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_count = df.select(count_distinct(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kni93BKXXld",
        "outputId": "091bf6b8-e8a6-4f8b-c1c1-49c737ca77ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|count(DISTINCT value)|\n",
            "+---------------------+\n",
            "|                    4|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqujSyXcXx9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes:\n",
        "* Handling Nulls: The count function will count only non-null values, while sum, avg, max, and min will ignore null values in their calculations.\n",
        "* Performance: Aggregate functions can be resource-intensive, especially on large datasets. Using the appropriate partitioning can improve performance.\n",
        "* Use Cases:\n",
        "  * **Summation:** Useful for calculating total sales, total revenue, etc.\n",
        "  * **Average:** Helpful for finding average metrics like average sales per day.\n",
        "  * **Count:** Useful for counting occurrences, such as the number of transactions.\n",
        "  * **Max/Min:** Helps to determine the highest and lowest values, such as maximum  sales on a specific day.\n",
        "  * **Distinct Count:** Useful for finding unique items, like unique customers or products.\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "xaM2BXVlX4_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Page 45 to be continued\n"
      ],
      "metadata": {
        "id": "Cv1Ami_IYYoC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51WAlJxrYltE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}