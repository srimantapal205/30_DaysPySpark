{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K9R9pyy1gU2Z"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with a longer timeout\n",
        "# drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "\n",
        "# df_employee_data = \"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\"\n",
        "# employeeSechema = StructType([\n",
        "#     StructField(\"ID\",IntegerType() ,True),\n",
        "#     StructField(\"Name\",StringType() ,True),\n",
        "#     StructField(\"Age\",IntegerType() ,True),\n",
        "#     StructField(\"Salary\",FloatType() ,True),\n",
        "#     StructField(\"Joining_Date\",DateType() ,True),\n",
        "#     StructField(\"Department\",StringType() ,True),\n",
        "#     StructField(\"Performance_Rating\",IntegerType() ,True),\n",
        "#     StructField(\"Email\",StringType() ,True),\n",
        "#     StructField(\"Address\",StringType() ,True),\n",
        "#     StructField(\"Phone\",StringType() ,True)\n",
        "\n",
        "# ])\n",
        "# # Load the DataFrame with the defined schema\n",
        "# #df = spark.read.csv(path=df_employee_data, header=True, schema=employeeSechema)\n",
        "# df = spark.read.load(path=\"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\", format=\"csv\", header = True, schema=employeeSechema)\n",
        "# df.printSchema()\n",
        "# df.show(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate function in Dataframe – Part 1"
      ],
      "metadata": {
        "id": "knP5wytcsBpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample data\n",
        "data = [\n",
        "      Row(id=1, value=10),\n",
        "      Row(id=2, value=20),\n",
        "      Row(id=3, value=30),\n",
        "      Row(id=4, value=None),\n",
        "      Row(id=5, value=40),\n",
        "      Row(id=6, value=20)\n",
        "   ]\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "# Show the DataFrame\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt1te3ktVd2a",
        "outputId": "78034df7-4c56-437d-ec1b-88609e4456ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id|value|\n",
            "+---+-----+\n",
            "|  1|   10|\n",
            "|  2|   20|\n",
            "|  3|   30|\n",
            "|  4| NULL|\n",
            "|  5|   40|\n",
            "|  6|   20|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Summation (sum): Sums up the values in a specified column."
      ],
      "metadata": {
        "id": "hhNBHWhQV_IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_sum = df.select(sum(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw9-mHgqWA8l",
        "outputId": "02323dec-bdc3-4b8a-82c1-3ad235049223"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|sum(value)|\n",
            "+----------+\n",
            "|       120|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.average of the values in a specified column."
      ],
      "metadata": {
        "id": "ymdYr8jCWe2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avarage_value = df.select(avg(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNZrE5gGWN1G",
        "outputId": "16cf7e63-3ddd-4679-fe54-cd2fe4c253b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|avg(value)|\n",
            "+----------+\n",
            "|      24.0|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Count (count): Counts the number of non-null values in a specified column."
      ],
      "metadata": {
        "id": "RSh6ZXv0Wu_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_null_count = df.select(count(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXAycrynWrV7",
        "outputId": "c5b9bdc5-bb2a-476e-a7a5-1a6565a6a06b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|count(value)|\n",
            "+------------+\n",
            "|           5|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.Maximum (max) and Minimum (min):\n",
        "* Finds the maximum and minimum values in a specified column"
      ],
      "metadata": {
        "id": "pE-6Pe-GW_z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_min_value = df.select(max(\"value\"), min(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL8AuZS5W-ep",
        "outputId": "7da09430-d3ad-42e1-c155-9db276500109"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|max(value)|min(value)|\n",
            "+----------+----------+\n",
            "|        40|        10|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distinct Values Count (countDistinct):\n",
        "  * Counts the number of distinct values in a specified column."
      ],
      "metadata": {
        "id": "2loPSMbCXfNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_count = df.select(count_distinct(\"value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kni93BKXXld",
        "outputId": "8d0f78ef-ac3e-40d8-9aee-cbd757ea2acc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|count(DISTINCT value)|\n",
            "+---------------------+\n",
            "|                    4|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqujSyXcXx9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes:\n",
        "* Handling Nulls: The count function will count only non-null values, while sum, avg, max, and min will ignore null values in their calculations.\n",
        "* Performance: Aggregate functions can be resource-intensive, especially on large datasets. Using the appropriate partitioning can improve performance.\n",
        "* Use Cases:\n",
        "  * **Summation:** Useful for calculating total sales, total revenue, etc.\n",
        "  * **Average:** Helpful for finding average metrics like average sales per day.\n",
        "  * **Count:** Useful for counting occurrences, such as the number of transactions.\n",
        "  * **Max/Min:** Helps to determine the highest and lowest values, such as maximum  sales on a specific day.\n",
        "  * **Distinct Count:** Useful for finding unique items, like unique customers or products.\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "xaM2BXVlX4_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate function in Dataframe – Part 2"
      ],
      "metadata": {
        "id": "tPgx-V83NvlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"AggregationExamples\").getOrCreate()\n",
        "# Sample data\n",
        "dataItem = [\n",
        "    (\"HR\", 10000, 500, \"John\"),\n",
        "    (\"Finance\", 20000, 1500, \"Doe\"),\n",
        "    (\"HR\", 15000, 1000, \"Alice\"),\n",
        "    (\"Finance\", 25000, 2000, \"Eve\"),\n",
        "    (\"HR\", 20000, 1500, \"Mark\")\n",
        "    ]\n",
        "# Define schema\n",
        "schema = StructType([\n",
        "     StructField(\"department\", StringType(), True),\n",
        "     StructField(\"salary\", IntegerType(), True),\n",
        "     StructField(\"bonus\", IntegerType(), True),\n",
        "     StructField(\"employee_name\", StringType(), True)\n",
        "     ])\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(dataItem, schema)\n",
        "df.show()\n"
      ],
      "metadata": {
        "id": "Cv1Ami_IYYoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0371bff-5881-410d-bc55-a052fdd7bc4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+-----+-------------+\n",
            "|department|salary|bonus|employee_name|\n",
            "+----------+------+-----+-------------+\n",
            "|        HR| 10000|  500|         John|\n",
            "|   Finance| 20000| 1500|          Doe|\n",
            "|        HR| 15000| 1000|        Alice|\n",
            "|   Finance| 25000| 2000|          Eve|\n",
            "|        HR| 20000| 1500|         Mark|\n",
            "+----------+------+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Grouped Aggregation"
      ],
      "metadata": {
        "id": "Zh_AXtNMO5Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.groupBy(\"department\").agg(\n",
        "    sum(\"salary\").alias(\"Total_Sum_Salary\"),\n",
        "    avg(\"salary\").alias(\"Avaarage_Salary\"),\n",
        "    max(\"salary\").alias(\"Max_Salary\"),\n",
        "    min(\"salary\").alias(\"Min_Salary\")\n",
        ").show()"
      ],
      "metadata": {
        "id": "51WAlJxrYltE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5e3840-f1fc-452c-c0d3-9e17e8db1787"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+---------------+----------+----------+\n",
            "|department|Total_Sum_Salary|Avaarage_Salary|Max_Salary|Min_Salary|\n",
            "+----------+----------------+---------------+----------+----------+\n",
            "|        HR|           45000|        15000.0|     20000|     10000|\n",
            "|   Finance|           45000|        22500.0|     25000|     20000|\n",
            "+----------+----------------+---------------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Multiple Aggregations"
      ],
      "metadata": {
        "id": "KnW9Eq3tQtKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"department\").agg(\n",
        "    sum(\"salary\").alias(\"Total_Sum_Salary\"),\n",
        "    avg(\"bonus\").alias(\"Avaarage_Bonus\"),\n",
        "    max(\"salary\").alias(\"Max_Salary\"),\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrL2x05mQioI",
        "outputId": "a68c72df-b977-4696-b5c6-3c6af51b83f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+--------------+----------+\n",
            "|department|Total_Sum_Salary|Avaarage_Bonus|Max_Salary|\n",
            "+----------+----------------+--------------+----------+\n",
            "|        HR|           45000|        1000.0|     20000|\n",
            "|   Finance|           45000|        1750.0|     25000|\n",
            "+----------+----------------+--------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Concatenate Strings"
      ],
      "metadata": {
        "id": "_klEEX7-RMrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.agg(concat_ws(\", \", collect_list(\"employee_name\")).alias(\"concatenated_names\")).show(trancate = False)\n",
        "47 page"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Pke2R3qgROQ8",
        "outputId": "aceaeb23-0f84-433e-f230-3415856caeae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DataFrame.show() got an unexpected keyword argument 'trancate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-936f0cfda144>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_ws\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employee_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"concatenated_names\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrancate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: DataFrame.show() got an unexpected keyword argument 'trancate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXCZc1LOR1b0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}