{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## PySpark COde Practice"
      ],
      "metadata": {
        "id": "c2L-0y-LDFIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "dVz3VjwEDKo_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial Saprk Session\n",
        "spark = SparkSession.builder.appName(\"PySparkPractice\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "_tiWFtKPDTmN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"1/1/2023\", \"C1\", 20),\n",
        "    (\"1/1/2023\", \"C2\", 20),\n",
        "    (\"1/2/2023\", \"C2\", 50),\n",
        "    (\"1/2/2023\", \"C3\", 12),\n",
        "    (\"1/3/2023\", \"C4\", 20),\n",
        "    (\"1/3/2023\", \"C5\", 100),\n",
        "    (\"1/3/2023\", \"C1\", 123),\n",
        "]\n",
        "column = ['Date_fld', 'Custome_name', 'Amount']\n",
        "\n",
        "df = spark.createDataFrame(data, column)\n",
        "df.show()\n",
        "\n",
        "# Convert date in proper format\n",
        "df = df.withColumn(\"Date_fld\", to_date(col(\"Date_fld\"), \"M/d/yyyy\"))\n",
        "df.show()\n",
        "\n",
        "# Define window partition by customer orderd by date\n",
        "window_space = Window.partitionBy('Custome_name').orderBy('Date_fld')\n",
        "\n",
        "#Assign row number within each customer number\n",
        "df = df.withColumn('Row_Number', row_number().over(window_space))\n",
        "df.show()\n",
        "\n",
        "#filter only new customer\n",
        "df_new_custome = df.filter(col('Row_Number') == 1)\n",
        "df_new_custome.show()\n",
        "\n",
        "# Count distinct new customers per date\n",
        "result_df = df_new_custome.groupBy('Date_fld').agg(countDistinct('Custome_name').alias('Price_Count'))\n",
        "result_df.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZQ59NvmKDZ3i",
        "outputId": "3a6b8802-29b0-4653-d1ac-cff92436276e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+------+\n",
            "|Date_fld|Custome_name|Amount|\n",
            "+--------+------------+------+\n",
            "|1/1/2023|          C1|    20|\n",
            "|1/1/2023|          C2|    20|\n",
            "|1/2/2023|          C2|    50|\n",
            "|1/2/2023|          C3|    12|\n",
            "|1/3/2023|          C4|    20|\n",
            "|1/3/2023|          C5|   100|\n",
            "|1/3/2023|          C1|   123|\n",
            "+--------+------------+------+\n",
            "\n",
            "+----------+------------+------+\n",
            "|  Date_fld|Custome_name|Amount|\n",
            "+----------+------------+------+\n",
            "|2023-01-01|          C1|    20|\n",
            "|2023-01-01|          C2|    20|\n",
            "|2023-01-02|          C2|    50|\n",
            "|2023-01-02|          C3|    12|\n",
            "|2023-01-03|          C4|    20|\n",
            "|2023-01-03|          C5|   100|\n",
            "|2023-01-03|          C1|   123|\n",
            "+----------+------------+------+\n",
            "\n",
            "+----------+------------+------+----------+\n",
            "|  Date_fld|Custome_name|Amount|Row_Number|\n",
            "+----------+------------+------+----------+\n",
            "|2023-01-01|          C1|    20|         1|\n",
            "|2023-01-03|          C1|   123|         2|\n",
            "|2023-01-01|          C2|    20|         1|\n",
            "|2023-01-02|          C2|    50|         2|\n",
            "|2023-01-02|          C3|    12|         1|\n",
            "|2023-01-03|          C4|    20|         1|\n",
            "|2023-01-03|          C5|   100|         1|\n",
            "+----------+------------+------+----------+\n",
            "\n",
            "+----------+------------+------+----------+\n",
            "|  Date_fld|Custome_name|Amount|Row_Number|\n",
            "+----------+------------+------+----------+\n",
            "|2023-01-01|          C1|    20|         1|\n",
            "|2023-01-01|          C2|    20|         1|\n",
            "|2023-01-02|          C3|    12|         1|\n",
            "|2023-01-03|          C4|    20|         1|\n",
            "|2023-01-03|          C5|   100|         1|\n",
            "+----------+------------+------+----------+\n",
            "\n",
            "+----------+-----------+\n",
            "|  Date_fld|Price_Count|\n",
            "+----------+-----------+\n",
            "|2023-01-01|          2|\n",
            "|2023-01-02|          1|\n",
            "|2023-01-03|          2|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pyspark code to solve"
      ],
      "metadata": {
        "id": "xFATEYxtcqFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Craete Spark Session\n",
        "spark2 = SparkSession\\\n",
        ".builder\\\n",
        ".config('spark.shuffle.useOldFetchers', 'true')\\\n",
        ".config('spark.ui.port','0')\\\n",
        ".config('spark.sql.warehouse.dir', '/user/itv008042/warehouse')\\\n",
        ".enableHiveSupport()\\\n",
        ".master('yarn')\\\n",
        ".appName('PySparkPractice')\\\n",
        ".getOrCreate()\n",
        "\n",
        "#Create Schema\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"ActorId\", IntegerType(), True),\n",
        "    StructField(\"DirectorId\", IntegerType(), True),\n",
        "    StructField(\"TimeStamp\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "data = [\n",
        "    (1,1,0),\n",
        "    (1,1,1),\n",
        "    (1,1,2),\n",
        "    (1,2,3),\n",
        "    (1,2,4),\n",
        "    (1,1,5),\n",
        "    (1,1,6)\n",
        "]\n",
        "\n",
        "# Create Data frame\n",
        "df = spark2.createDataFrame(data, schema)\n",
        "df.show()\n"
      ],
      "metadata": {
        "id": "TfJPZ3n2ECGf",
        "outputId": "1b89e383-7c48-458a-c322-475bc9c5ce87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+\n",
            "|ActorId|DirectorId|TimeStamp|\n",
            "+-------+----------+---------+\n",
            "|      1|         1|        0|\n",
            "|      1|         1|        1|\n",
            "|      1|         1|        2|\n",
            "|      1|         2|        3|\n",
            "|      1|         2|        4|\n",
            "|      1|         1|        5|\n",
            "|      1|         1|        6|\n",
            "+-------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Group By ActorId','DirectorId"
      ],
      "metadata": {
        "id": "YiiczhnSfO8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_group = df.groupBy('ActorId', 'DirectorId').count()\n",
        "df_group.show()"
      ],
      "metadata": {
        "id": "rIjzrc2scw4h",
        "outputId": "717ceec3-133e-4521-8e46-8ab9b4a25dfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----+\n",
            "|ActorId|DirectorId|count|\n",
            "+-------+----------+-----+\n",
            "|      1|         1|    5|\n",
            "|      1|         2|    2|\n",
            "+-------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_group.filter(df_group['count']> 3).show()\n"
      ],
      "metadata": {
        "id": "rgvPYNvKfnvN",
        "outputId": "cc16b1b6-2c66-4512-f6be-191083548135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----+\n",
            "|ActorId|DirectorId|count|\n",
            "+-------+----------+-----+\n",
            "|      1|         1|    5|\n",
            "+-------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFAj-6DliTqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}