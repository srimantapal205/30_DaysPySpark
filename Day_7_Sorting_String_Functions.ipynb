{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijVRjfSU2ihU"
      },
      "source": [
        "**a structured set of notes with code to cover changing data types, filtering data, and handling unique/distinct values in PySpark using the employee data:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKKH4zhWIOQV",
        "outputId": "24cc3218-217e-4e2e-e3b4-6edd9b67e3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "root\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Salary: float (nullable = true)\n",
            " |-- Joining_Date: date (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Performance_Rating: integer (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- Address: string (nullable = true)\n",
            " |-- Phone: string (nullable = true)\n",
            "\n",
            "+---+-------------+----+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "| ID|         Name| Age| Salary|Joining_Date| Department|Performance_Rating|               Email|           Address|       Phone|\n",
            "+---+-------------+----+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "|  1|Alice Johnson|  29|75000.0|  2021-03-15|Engineering|                 4|alice.johnson@exa...|123 Elm Street, NY|123-456-7890|\n",
            "|  2|    Bob Smith|  35|85000.0|  2020-08-20|  Marketing|                 5|bob.smith@example...|456 Oak Avenue, LA|987-654-3210|\n",
            "|  3|  Cathy Brown|  42|95000.0|  2019-11-10|    Finance|                 3|cathy.brown@examp...| 789 Pine Road, TX|567-890-1234|\n",
            "|  4|  David White|  30|67000.0|  2022-01-05|         HR|                 4|david.white@examp...|234 Maple Lane, IL|345-678-9012|\n",
            "|  5|    Eva Green|  28|72000.0|  2023-06-22|Engineering|                 5|eva.green@example...|321 Birch Blvd, FL|234-567-8901|\n",
            "|  6|        Alice|  29|55000.0|  2024-12-06|    Finance|                 6|   alice@example.com|235 Maple Lane, IL|345-678-9013|\n",
            "|  7|          Bob|NULL|38000.0|  2024-05-23|         HR|                 7|                Null|322 Birch Blvd, FL|234-567-8902|\n",
            "|  8|      Charlie|  27|21000.0|  2024-11-07|Engineering|                 8|     charlie@xyz.com|              Null|345-678-9014|\n",
            "|  9|         Emma|  31|40000.0|  2024-04-23|    Finance|                 9|        emma@abc.com|122 Elm Street, NY|234-567-8903|\n",
            "+---+-------------+----+-------+------------+-----------+------------------+--------------------+------------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with a longer timeout\n",
        "drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "\n",
        "df_employee_data = \"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\"\n",
        "employeeSechema = StructType([\n",
        "    StructField(\"ID\",IntegerType() ,True),\n",
        "    StructField(\"Name\",StringType() ,True),\n",
        "    StructField(\"Age\",IntegerType() ,True),\n",
        "    StructField(\"Salary\",FloatType() ,True),\n",
        "    StructField(\"Joining_Date\",DateType() ,True),\n",
        "    StructField(\"Department\",StringType() ,True),\n",
        "    StructField(\"Performance_Rating\",IntegerType() ,True),\n",
        "    StructField(\"Email\",StringType() ,True),\n",
        "    StructField(\"Address\",StringType() ,True),\n",
        "    StructField(\"Phone\",StringType() ,True)\n",
        "\n",
        "])\n",
        "# Load the DataFrame with the defined schema\n",
        "#df = spark.read.csv(path=df_employee_data, header=True, schema=employeeSechema)\n",
        "df = spark.read.load(path=\"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\", format=\"csv\", header = True, schema=employeeSechema)\n",
        "df.printSchema()\n",
        "df.show(50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNjIP5dVzPP/8z9L49E1jOC",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
